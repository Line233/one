{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598933609103",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown --id '1xYbIkdUR_XYKYE868EltaqZJAcPH-7Cv' # 下載資料集\n",
    "# !unzip hidden.zip -d ./data\n",
    "# !git clone https://github.com/Line233/one.git ./one\n",
    "# !mv ./one/tool.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import tool\n",
    "%matplotlib inline\n",
    "import importlib\n",
    "importlib.reload(tool)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_data(data.Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x=x.float()\n",
    "        self.y=y.long()\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self,index):\n",
    "        if self.y is not None:\n",
    "            return self.x[index].reshape([-1]),self.y[index].long()\n",
    "        else:\n",
    "            return self.x[index].reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_single(nn.Module):\n",
    "    def __init__(self,input_a,hidden_a,device=torch.device('cpu'),rand_seed=10):\n",
    "        super(mnist_single,self).__init__()\n",
    "        torch.manual_seed(rand_seed)\n",
    "        self.device=device\n",
    "        self.hidden_a=hidden_a\n",
    "        self.linear1=nn.Linear(input_a,self.hidden_a)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.linear2=nn.Linear(self.hidden_a,10)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        self.lossF=nn.CrossEntropyLoss()\n",
    "    def forward(self,input):\n",
    "        input=input.to(self.device)\n",
    "        res=self.linear1(input)\n",
    "        res=self.relu(res)\n",
    "        res=self.linear2(res)\n",
    "        res=self.softmax(res)\n",
    "        return res\n",
    "\n",
    "    def expand(self):\n",
    "        new_linear=nn.Linear(self.linear1.in_features,self.linear1.out_features+1).to(self.device)\n",
    "        new_linear2=nn.Linear(self.linear2.in_features+1,self.linear2.out_features).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            # weight=np.zeros([self.linear1.out_features])\n",
    "            # for i in range(self.linear1.out_features):\n",
    "            #     weight[i]=abs(self.linear1.weight.data[i]*self.linear2.weight.data[:,i])\n",
    "            index=0\n",
    "\n",
    "            weight=self.__expand_weight_down__(self.linear1.weight.data.detach(),index)\n",
    "            bias=self.__expand_weight_down__(self.linear1.bias.data.detach(),index)\n",
    "            new_linear.weight.data=weight\n",
    "            new_linear.bias.data=bias\n",
    "\n",
    "            weight2=self.__expand_weight_up__(self.linear2.weight.data.detach(),index)\n",
    "            new_linear2.weight.data=weight2\n",
    "\n",
    "        self.linear1=new_linear.to(self.device)\n",
    "        self.linear2=new_linear2.to(self.device)\n",
    "        return\n",
    "\n",
    "    def __expand_weight_up__(self,weight,index):\n",
    "        with torch.no_grad():\n",
    "            shape=torch.tensor(weight.shape)\n",
    "            shape[1]=1\n",
    "            # new_weight=weight.data[:,index].reshape(shape.tolist()).clone()*0.4\n",
    "            # new_weight=torch.zeros(shape.tolist()).to(self.device)+0.001\n",
    "            # new_weight=torch.normal(0,0.05,shape.tolist()).to(self.device)\n",
    "            # new_weight=torch.sum(weight,dim=1).reshape(shape.tolist()).to(self.device)\n",
    "            std_mean=torch.std_mean(weight,dim=1)\n",
    "            new_weight=torch.normal(std_mean[1],std_mean[0]).reshape(shape.tolist()).to(self.device)\n",
    "            weight.data[:,index]*=1\n",
    "            new_weight=torch.cat([weight,new_weight],dim=1)\n",
    "            new_weight/=new_weight.shape[1]\n",
    "        return new_weight\n",
    "\n",
    "    def __expand_weight_down__(self,weight,index):\n",
    "        with torch.no_grad():\n",
    "            shape=torch.tensor(weight.shape)\n",
    "            shape[0]=1\n",
    "            # new_weight=weight[index].reshape(shape.tolist()).clone()*0.4\n",
    "            # new_weight=torch.zeros(shape.tolist()).to(self.device)+0.001\n",
    "            # new_weight=torch.normal(0,0.05,shape.tolist()).to(self.device)\n",
    "            # new_weight=torch.sum(weight,dim=0).reshape(shape.tolist()).to(self.device)/weight.shape[0]\n",
    "            std_mean=torch.std_mean(weight,dim=0)\n",
    "            new_weight=torch.normal(std_mean[1],std_mean[0]).reshape(shape.tolist()).to(self.device)\n",
    "            weight.data[index]*=1\n",
    "            new_weight=torch.cat([weight,new_weight],dim=0)\n",
    "        return new_weight\n",
    "    \n",
    "    def reset_loss_record(self):\n",
    "        self.__total_loss__=0.0\n",
    "        self.__right_num__=0\n",
    "        self.__total_num__=0\n",
    "    def computeloss(self,x,y,res):\n",
    "        y=y.to(self.device)\n",
    "        loss=self.lossF(res,y)\n",
    "        self.__total_loss__+=loss.tolist()*len(x)\n",
    "        a=res.argmax(dim=1)\n",
    "        self.__right_num__+=torch.eq(a,y).sum().tolist()\n",
    "        self.__total_num__+=len(x)\n",
    "        return loss\n",
    "    def get_loss(self):\n",
    "        return self.__total_loss__/self.__total_num__,self.__right_num__/self.__total_num__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_cov(nn.Module):\n",
    "    def __init__(self,input_a,input_channel,device=torch.device('cpu'),rand_seed=10):\n",
    "        super(mnist_cov,self).__init__()\n",
    "        torch.manual_seed(rand_seed)\n",
    "        self.device=device\n",
    "        self.inputa=input_a\n",
    "        self.input_channel=input_channel\n",
    "\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Conv2d(1,4,3,1,1),\n",
    "            nn.MaxPool2d(3,2),\n",
    "            nn.Conv2d(4,16,3,1,1),\n",
    "            nn.MaxPool2d(3,2)\n",
    "        )\n",
    "        self.out2=nn.Sequential(\n",
    "            nn.Linear(16,10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.lossF=nn.CrossEntropyLoss()\n",
    "        pass\n",
    "    def forward(self,input):\n",
    "        input=input.reshape([-1,self.input_channel,self.inputa,self.inputa]).to(self.device)\n",
    "        res=self.out(input)\n",
    "        res= res.reshape([-1,16])\n",
    "        res=self.out2(res)\n",
    "        return res\n",
    "    def reset_loss_record(self):\n",
    "        self.__total_loss__=0.0\n",
    "        self.__right_num__=0\n",
    "        self.__total_num__=0\n",
    "    def computeloss(self,x,y,res):\n",
    "        y=y.to(self.device)\n",
    "        loss=self.lossF(res,y)\n",
    "        self.__total_loss__+=loss.tolist()*len(x)\n",
    "        a=res.argmax(dim=1)\n",
    "        self.__right_num__+=torch.eq(a,y).sum().tolist()\n",
    "        self.__total_num__+=len(x)\n",
    "        return loss\n",
    "    def get_loss(self):\n",
    "        return self.__total_loss__/self.__total_num__,self.__right_num__/self.__total_num__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def early_end(records,last,mini=1000,step=200,bias=0):\n",
    "#     if len(records)-last<mini:\n",
    "#         return False\n",
    "#     elif records[-step][2]-records[-1][2]-bias>0:\n",
    "#         return False\n",
    "#     else:return True\n",
    "# def dlr1(index):\n",
    "#     # return max(pow(0.1,index+3),pow(0.1,5))\n",
    "#     return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_out():   \n",
    "    !zip -vr out.zip  ./out/\n",
    "    tool.download('out.zip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(dataset,num):\n",
    "    arr=np.ones(10)\n",
    "    res=[]\n",
    "    i=0\n",
    "    total=0\n",
    "    while True:\n",
    "        k=int(dataset[i])\n",
    "        if arr[k]<=num:\n",
    "            res.append(i)\n",
    "            arr[k]+=1\n",
    "            total+=1\n",
    "        if total==num*10:\n",
    "            break\n",
    "        i+=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_set(dataset,num):\n",
    "    res=count(dataset.y,num)\n",
    "    return mnist_data(dataset.x[res],dataset.y[res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version=216\n",
    "batch_size=128\n",
    "epoch=1000\n",
    "epoch_per=1\n",
    "lr=0.001\n",
    "hidden=10\n",
    "ee_mini=40\n",
    "ee_step=20\n",
    "ee_bias=0\n",
    "shot=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=torch.load('./data/train_hidden')\n",
    "valid_data=torch.load('./data/valid_hidden')\n",
    "test_data=torch.load('./data/test_hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=count_set(train_data,shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data=mnist_data(valid_data[0:100][0].reshape([-1,10,10]),valid_data[0:100][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.tensor([1,2]).to(device)\n",
    "labels=['train_loss','train_precise','valid_loss','valid_precise']\n",
    "select_loss=[True,False,True,False]\n",
    "select_precise=[False,True,False,True]\n",
    "folder_out='./out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_name(version,name):\n",
    "    return  f'{folder_out}{version:04}/{name}'\n",
    "if not os.path.exists(out_name(version,'')):\n",
    "    os.makedirs(out_name(version,''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_end(records,last,mini=ee_mini,step=ee_step,bias=ee_bias):\n",
    "    if len(records)-last<mini:\n",
    "        return False\n",
    "    elif records[-step][2]-records[-1][2]-bias>0:\n",
    "        return False\n",
    "    else:return True\n",
    "def dlr1(index):\n",
    "    # return max(pow(0.1,index+3),pow(0.1,5))\n",
    "    return 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN_CONV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=mnist_cov(10,1,device).to(device)\n",
    "record1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "record1+=tool.TrainTool.train_epoch(model,simple_data,valid_data,lr=0.0001,batch_size=1000,epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc1=tool.learning_curve(record1,reshape=True)\n",
    "lc1.save('./data/conv_lc.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN_SINGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_single=mnist_single(100,hidden,device=device).to(device)\n",
    "res=[]\n",
    "optim=torch.optim.Adam(model_single.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "f=tool.TrainTool.train_epoch(model_single,train_data,valid_data,res,lr=lr,batch_size=batch_size,epoch=epoch,epoch_per=epoch_per,optim=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_lc=tool.learning_curve(res,labels,reshape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_lc.save(out_name(version,'single_s_lc.npy'))\n",
    "torch.save(model_single,out_name(version,'single_s_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_lc.draw(select=select_precise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADAM_RESET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_model=mnist_single(100,hidden,device).to(device)\n",
    "ar_record=[]\n",
    "ar_reset=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "f=tool.TrainTool.train_adam_reset(ar_model,train_data,valid_data,ar_record,ar_reset,dlr=dlr1,batch_size=batch_size,epoch=epoch,epoch_per=epoch_per,early_end=early_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_lc=tool.learning_curve(ar_record,reshape=True)\n",
    "ar_lc.add_vlines(ar_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_lc.save(out_name(version,'ar_lc.npy'))\n",
    "torch.save(ar_model,out_name(version,'ar_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_lc.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_model=mnist_single(100,hidden,device).to(device)\n",
    "ex_record=[]\n",
    "ex_ex=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "f=tool.TrainTool.train_expand(ex_model,train_data,valid_data,ex_record,ex_ex,dlr=dlr1,batch_size=batch_size,epoch=epoch,epoch_per=epoch_per,early_end=early_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ex_lc=tool.learning_curve(ex_record,reshape=True)\n",
    "ex_lc.add_vlines(ex_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_lc.save(out_name(version,'ex_lc.npy'))\n",
    "torch.save(ex_model,out_name(version,'ex_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_lc.draw(select=select_precise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ex_lc.draw_range(block_num=1,select=select_precise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNING_CURVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_lc=tool.learning_curve.load2(out_name(version,'ex_lc.npy'),['ex_'+label[:-8] for label in labels],title='ex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_lc.draw(select=select_precise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_s_lc=tool.learning_curve.load2(out_name(version,'single_s_lc.npy'),['s_'+label[:-8] for label in labels],title='single')\n",
    "# single_e_lc=tool.learning_curve.load2(out_name(version,'single_e_lc.npy'),['e_'+label[:-8] for label in labels],title='single')\n",
    "# # ar_lc=tool.learning_curve.load2(out_name(version,'ar_lc.npy'),['ar_'+label[:-8] for label in labels],title='ar')\n",
    "ex_lc2=tool.learning_curve.load2(out_name(version,'ex_lc.npy'),['ex216_'+label[:-8] for label in labels],title='ex')\n",
    "ex_lc=tool.learning_curve.load2(out_name(213,'ex_lc.npy'),['ex213_'+label[:-8] for label in labels],title='ex')\n",
    "\n",
    "compare_lc=tool.learning_curve([])\n",
    "compare_lc.add_curve(\n",
    "    [\n",
    "        # single_s_lc[1],\n",
    "        # single_e_lc[1],\n",
    "        ex_lc[1],\n",
    "        ex_lc2[1],\n",
    "        # ar_lc[1],\n",
    "        # single_s_lc[3],\n",
    "        # single_e_lc[3],\n",
    "        ex_lc[3],\n",
    "        ex_lc2[3]\n",
    "        # ar_lc[3]\n",
    "    ]\n",
    "    )\n",
    "compare_lc.add_vlines(ex_lc2.vlines)\n",
    "# compare_lc.add_vlines(ex_lc.vlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare_lc.draw()\n",
    "compare_lc.draw_range(block_num=5,expand=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ex_lc.draw_range(block_num=10,expand=20,select=[0,0,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a=10\n",
    "b=a+3\n",
    "w_lc=tool.learning_curve(ex_model.linear1.weight.data[a:b],title=f'ex_linear1[{a}-{b}]')\n",
    "w_lc.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool.colab_tool.zip('out','./out/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool.colab_tool.download_drive(['out.zip'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool.colab_tool.download(['out_zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function ClickConnect() {\n",
    "  console.log('Working')\n",
    "  document\n",
    "    .querySelector('#top-toolbar > colab-connect-button')\n",
    "    .shadowRoot.querySelector('#connect')\n",
    "    .click()\n",
    "}\n",
    "\n",
    "setInterval(ClickConnect, 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function ClickConnect() {\n",
    "#   console.log('Working')\n",
    "#   document\n",
    "#     .querySelector('#top-toolbar > colab-connect-button')\n",
    "#     .shadowRoot.querySelector('#connect')\n",
    "#     .click()\n",
    "# }\n",
    "# var numberOfTimes = 3;\n",
    "# delay = 1000*60*50;\n",
    "\n",
    "# for (let i = 0; i < numberOfTimes; i++) {\n",
    "#     setTimeout( doSomething, delay * i);\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([[1,3],[2,4]],dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(a,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.std_mean(a,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}