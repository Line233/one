{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<module 'tool' from '/Users/jacky/Documents/code/my3/one/tool.py'>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import tool\n",
    "%matplotlib inline\n",
    "import importlib\n",
    "importlib.reload(tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_data(data.Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x=x.float()\n",
    "        self.y=y.float()\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self,index):\n",
    "        if self.y is not None:\n",
    "            return self.x[index].reshape([-1]),self.y[index]\n",
    "        else:\n",
    "            return self.x[index].reshape([-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Auto_Learning(nn.Module):\n",
    "    def __init__(self,input_a,hidden1_a,hidden2_a,hidden3_a,rand_seed=10,device=torch.device('cpu')):\n",
    "        torch.manual_seed(rand_seed)\n",
    "        super(Auto_Learning,self).__init__()\n",
    "        input_a=input_a*input_a\n",
    "        hidden1_a*=hidden1_a\n",
    "        hidden2_a*=hidden2_a\n",
    "        hidden3_a*=hidden3_a\n",
    "        self.device=device\n",
    "\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(input_a,hidden1_a),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden1_a,hidden2_a),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden2_a,hidden3_a),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden3_a,hidden2_a),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden2_a,hidden1_a),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden1_a,input_a),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.lossF=nn.MSELoss()\n",
    "    def forward(self,input):\n",
    "        input=input.to(self.device)\n",
    "        return self.net(input)\n",
    "    \n",
    "    def trainF(self,train_data,valid_data,learning_rate=0.1,epoch=100,epoch_per=10,batch_size=128,optim=None):\n",
    "        lossF=self.lossF\n",
    "        if optim is None:\n",
    "            optim=torch.optim.Adam(self.parameters(),lr=learning_rate)\n",
    "        loader=data.DataLoader(train_data,batch_size=batch_size)\n",
    "        train_record=[]\n",
    "        valid_record=[]\n",
    "\n",
    "        for i in range(epoch):\n",
    "            train_loss=0.0\n",
    "            pb=tool.ProgressBar(epoch_per*len(train_data))\n",
    "            for k in range(epoch_per):\n",
    "                for x,_ in loader:\n",
    "                    x=x.to(device)\n",
    "                    optim.zero_grad()\n",
    "                    res=self(x)\n",
    "                    loss=lossF(res,x)\n",
    "                    loss.backward()\n",
    "                    optim.step()\n",
    "                    train_loss+=loss.tolist()*len(x)\n",
    "                    pb.step(len(x))\n",
    "                    pass\n",
    "            #compute\n",
    "            pb.end()\n",
    "            train_loss/=len(train_data)\n",
    "            train_loss/=epoch_per\n",
    "            train_record.append(train_loss)\n",
    "            valid_loss=self.valid(valid_data)\n",
    "            valid_record.append(valid_loss)\n",
    "            #print\n",
    "            print(f'{i}\\t{train_loss:.4f}\\t{valid_loss:.4f}')\n",
    "    \n",
    "        return train_record,valid_record\n",
    "    def valid(self,valid_data,batch_size=128):\n",
    "        lossF=self.lossF\n",
    "        loader=data.DataLoader(valid_data)\n",
    "        total_loss=0.0\n",
    "        for x,_ in loader:\n",
    "            x=x.to(self.device)\n",
    "            res=self(x)\n",
    "            loss=lossF(res,x).tolist()\n",
    "            total_loss+=loss*len(x)\n",
    "        return total_loss/len(valid_data)\n",
    "    def __half_farward__(self,input):\n",
    "        input=input.to(self.device)\n",
    "        net2=nn.Sequential(self.net[0:6])\n",
    "        res=net2(input)\n",
    "        return res\n",
    "    def get_code(self,input):\n",
    "        res=[]\n",
    "        loader=data.DataLoader(input,batch_size=1)\n",
    "        for x,_ in input:\n",
    "            hidden=self.__half_farward__(x)\n",
    "            res.append(hidden.tolist())\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mnist=torchvision.datasets.MNIST('./mnist',download=True)\n",
    "mnist=torchvision.datasets.MNIST('./mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x=tool.data_split(mnist.train_data,rand=20)\n",
    "train_y,test_y=tool.data_split(mnist.train_labels,rand=20)\n",
    "train_x,valid_x=tool.data_split(train_x,rand=10)\n",
    "train_y,valid_y=tool.data_split(train_y,rand=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=mnist_data(train_x,train_y)\n",
    "valid_data=mnist_data(valid_x,valid_y)\n",
    "test_data=mnist_data(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(len(valid_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTO_LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ALmodel=Auto_Learning(28,30,20,10,device=device).to(device)\n",
    "# print(ALmodel)\n",
    "ALmodel=torch.load('./data/al_model').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr,vr=ALmodel.trainF(train_data,valid_data,learning_rate=0.001,batch_size=10,epoch_per=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=100\n",
    "plt.matshow(ALmodel(train_data[a][0].reshape([-1])).reshape([28,28]).detach().cpu())\n",
    "plt.matshow(train_data[a][0].reshape([28,28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALmodel=torch.load('./data/al_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hidden=ALmodel.get_code(train_data)\n",
    "valid_hidden=ALmodel.get_code(valid_data)\n",
    "test_hidden=ALmodel.get_code(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2=mnist_data(torch.tensor(train_hidden),train_y.long())\n",
    "test_data2=mnist_data(torch.tensor(test_hidden),test_y.long())\n",
    "valid_data2=mnist_data(torch.tensor(valid_hidden),valid_y.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_data2,'./data/train_hidden')\n",
    "torch.save(valid_data2,'./data/valid_hidden')\n",
    "torch.save(test_data2,'./data/test_hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598457914466",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}